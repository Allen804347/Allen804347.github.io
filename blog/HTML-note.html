<!doctype html>
<html lang="zh-Hans" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">軒田機器學習筆記 | ${CODDEE}</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://allen804347.github.io/img/coddee-100.png"><meta data-rh="true" name="twitter:image" content="https://allen804347.github.io/img/coddee-100.png"><meta data-rh="true" property="og:url" content="https://allen804347.github.io/blog/HTML-note"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="軒田機器學習筆記 | ${CODDEE}"><meta data-rh="true" name="description" content="何謂機器學習"><meta data-rh="true" property="og:description" content="何謂機器學習"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-10-16T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://allen804347.github.io"><meta data-rh="true" property="article:tag" content="machine learning"><link data-rh="true" rel="icon" href="/img/coddee-100.png"><link data-rh="true" rel="canonical" href="https://allen804347.github.io/blog/HTML-note"><link data-rh="true" rel="alternate" href="https://allen804347.github.io/blog/HTML-note" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://allen804347.github.io/blog/HTML-note" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="${CODDEE} RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="${CODDEE} Atom Feed"><link rel="stylesheet" href="/assets/css/styles.12567a64.css">
<link rel="preload" href="/assets/js/runtime~main.c9a5b154.js" as="script">
<link rel="preload" href="/assets/js/main.a7efb3ed.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/coddee-100.png" alt="${CODDEE} Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/coddee-100.png" alt="${CODDEE} Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/about">About</a><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="最近博文导航"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/HTML-note">軒田機器學習筆記</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/front-end-performance">前端效能探討</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/rive-versus-lottie">Rive 與 Lottie</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/coffee-map">咖啡地圖</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/daily-uva-task">每日 C++ 練習</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">軒田機器學習筆記</h1><div class="container_mt6G margin-vert--md"><time datetime="2023-10-16T00:00:00.000Z" itemprop="datePublished">2023年10月16日</time> · <!-- -->阅读需 8 分钟</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://allen804347.github.io" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/avatar.jpg" alt="Allen Hsieh"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://allen804347.github.io" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Allen Hsieh</span></a></div><small class="avatar__subtitle" itemprop="description">Engineer</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><h2 class="anchor anchorWithStickyNavbar_LWe7" id="何謂機器學習">何謂機器學習<a href="#何謂機器學習" class="hash-link" aria-label="何謂機器學習的直接链接" title="何謂機器學習的直接链接">​</a></h2><p>對一份有特徵的資料進行判斷</p><p>舉例
人  =&gt; 身高 ,體重, 腰圍 -&gt; 是否過重, 是否健康
過往我們依賴專家的意見，如 BMI 異常或腰圍來判斷，但這樣的判斷模式，容易受限於規模，
身高 ,體重, 腰圍, 血紅素數值, 血小板數值...
體檢列表可以列出上千上百種指數，我們也可以針對各個數值判讀，通常每個數值也會也有對應的好壞區間，
但，假設，有一種人們還不知到的特殊的連結，在身高和血紅素數值間，身高介於 150 - 155 ，血紅素數值介於 12 - 12.25 ，
有高機率患有特殊疾病，
;  TODO</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="資料---結果--方法">資料 -&gt; 結果 = 方法<a href="#資料---結果--方法" class="hash-link" aria-label="資料 -&gt; 結果 = 方法的直接链接" title="資料 -&gt; 結果 = 方法的直接链接">​</a></h2><p>假設有一個被設計好的判斷方法可以判別問題的結果，我們是否能夠模仿這個方法？</p><p>先決條件是：這個方法我們還未知。
如果已經知道這個方法的確切模樣，那直接套用方法就好。</p><p>大量的資料很重要，需要反覆驗證，大量練習。
想要什麼樣的結果，如果沒辦法精準定義結果，你會訓練出好像可以又好像不行的東西。</p><p>{(xn, yn)} from f -&gt; ML -&gt; g
xn: 因
yn: 果
f: 神妙而不可知的因果關係
g: 我們對這種神妙的猜想</p><p>其中 yn 是 f 產生的。
透過 ML 找到跟 f 接近的 g。
換句話說，因果之間存在某種被規定好的關係，但這個神妙而不可知的因果關係我們沒辦法看透，所以只能透過資料和結果，自己腦補中間的關係。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="可能信無限多種">可能信無限多種<a href="#可能信無限多種" class="hash-link" aria-label="可能信無限多種的直接链接" title="可能信無限多種的直接链接">​</a></h2><p>hypothesis set
找到最好的 hypothesis 我們稱之為 g</p><h1>Lecture 2</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="perceptron">Perceptron<a href="#perceptron" class="hash-link" aria-label="Perceptron的直接链接" title="Perceptron的直接链接">​</a></h2><p>感知機，這個名字本身不重要，只是歷史因素遺留下來的慣用名字</p><p>g = sign(Sigma 1 ~ N(W_i <em> X_i) - threshold)
= sign(Sigma 0 ~ N(W_i </em> X_i)) // W_0 = -threshold, X_0 = 1
= sign(W^T*X)</p><h1>Lecture 10</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="基於二元結果的機率---logistic-regression">基於二元結果的機率 - logistic regression<a href="#基於二元結果的機率---logistic-regression" class="hash-link" aria-label="基於二元結果的機率 - logistic regression的直接链接" title="基於二元結果的機率 - logistic regression的直接链接">​</a></h2><p>想知道一個 0 ~ 1 的結果，不要二元的答案(true/false)，而是更抽象的機率(大 50% 代表更接近於 true，小於則接近 false )</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="執行上的困難以及折衷作法">執行上的困難，以及折衷作法<a href="#執行上的困難以及折衷作法" class="hash-link" aria-label="執行上的困難，以及折衷作法的直接链接" title="執行上的困難，以及折衷作法的直接链接">​</a></h2><p>實際很難拿到這種機率的真實資料(拿不到樂透號碼的開獎機率)，用 true == 1, false == 0 來當做有雜訊的答案，
e.g.
如果真實機率是 0.7(70%) 那這次拿到 true 代表答案(y)為 1 但有 0.3 的雜訊，如果拿到 false 代表答案(y)為 0 但有 0.7 的雜訊</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="sigmoid">sigmoid<a href="#sigmoid" class="hash-link" aria-label="sigmoid的直接链接" title="sigmoid的直接链接">​</a></h2><p>用 sigmoid 函數來做分數數轉換
透過 linear regression 算出來的原始分數，帶進 sigmoid 函數轉換成 0 ~ 1 的函數</p><p>s =&gt; linear regression 算出來的原始分數
θ(s) = e^s / 1 + e^s
分母分子同乘 1/e^s
= 1 / 1 + e^-s</p><p>因為 s 是 linear regression 算出來的原始分數，帶入 s = w^T <em> x
原本 h(x) = w^T </em> x
帶入 θ(s)
h&#x27;(x) = θ(h(x))
= 1 / 1 + e^-(w^T <em> x)
不要一堆次方符號用 exp 美化一下
= 1 / 1 + exp(-w^T </em> x)</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="fx-in-logistic-regression">f(x) in logistic regression<a href="#fx-in-logistic-regression" class="hash-link" aria-label="f(x) in logistic regression的直接链接" title="f(x) in logistic regression的直接链接">​</a></h2><p>logistic regression 是針對結果為 true 或 false 的機率
f(x) = P(+1|X) or f(x) = P(-1|X)
可以用這個來表達 f(x)
擴展 f(x) = P(y|X), y ∈ {+1, -1}</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="likelihood">Likelihood<a href="#likelihood" class="hash-link" aria-label="Likelihood的直接链接" title="Likelihood的直接链接">​</a></h3><p>P(y|x) = P(+1|x) + P(-1|x)
P(+1|x) := f(x)
P(-1|x) = 1 - f(x)</p><p>注意，這裡使用的是 := (定義符號)，與等號不同的是，定義代表假設的開端，
原則上等號要具有絕對的相等意義，
但定義不同，不需要具備絕對的概念，
以這裡為例，P(+1|x) := f(x) 代表定義 +1 的機率是 f(x)，
但不代表這兩者相等，只是假定接下來的推導是以 P(+1|x) := f(x) 為前提進行下去，
反之 P(-1|x) := f(x), P(+1|x) = 1 - f(x) 也可以作為開端進行推導。</p><p>D = {(x_1, y_1),(x_2, y_2), . . . ,(x_N, y_N)}
D = {(x_1, ◦),(x_2, ×), . . . ,(x_N, ×)}
這裡是在討論，當我們有真實資料 D，想向他的組成就是 x_i 對應 y_i 的資料集，
每個 y_i 不是 +1(◦) 就是(×)，可以表示成第二條式子。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="probability-that-f-generates-d">probability that f generates D<a href="#probability-that-f-generates-d" class="hash-link" aria-label="probability that f generates D的直接链接" title="probability that f generates D的直接链接">​</a></h4><p>思考 D 這個資料集出現的機率，茫茫資料中出現這樣的資料組的可能性。</p><p>P(x_1)f(x_1) <em> P(x_2)(1 − f(x_2)) </em> ... * P(x_N)(1 − f(x_N))</p><p>參考前面的式子 f(x_i) 代表結果為 ◦， (1 − f(x_i)) 代表結果為 ×。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="likelihood-that-h-generates-d">likelihood that h generates D<a href="#likelihood-that-h-generates-d" class="hash-link" aria-label="likelihood that h generates D的直接链接" title="likelihood that h generates D的直接链接">​</a></h4><p>P(x_1)h(x_1) <em> P(x_2)(1 − h(x_2)) </em> ... * P(x_N)(1 − h(x_N))</p><p>把 f 替換成 h，當然，h 不是 f，所以這裡想討論的是 h 有多接近 f。
所以我們會從 H (Hypothesis set) 挑一個最近像 f 的 h。
如果資料筆數夠多 (N 夠大)，h 應該會很接近 f，稱為大數似然法則。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="cross-entropy-error">Cross-Entropy Error<a href="#cross-entropy-error" class="hash-link" aria-label="Cross-Entropy Error的直接链接" title="Cross-Entropy Error的直接链接">​</a></h2><p>P(x_1)f(x_1) <em> P(x_2)(1 − f(x_2)) </em> ... <em> P(x_N)(1 − f(x_N))
v.s.
P(x_1)h(x_1) </em> P(x_2)(1 − h(x_2)) <em> ... </em> P(x_N)(1 − h(x_N))</p><p>兩者在 P(x_i) 的部分是一樣的，在後面的計算中，我們只在乎不一樣的部分 f(x_i) v.s. h(x_i)。</p><p>max of h =&gt; likelihood(logistic h) ∝ ∏(h(y_n <em> x_n), n = 1 to N)
max of w =&gt; likelihood(logistic w) ∝ ∏(θ(y_n </em> w^T <em> x_n), n = 1 to N)
max of w ∝ ln(∏(θ(y_n </em> w^T * x_n), n = 1 to N))</p><p>注意，這裡使用 ln 有幾個因素，</p><ol><li>為了解決連乘(∏)，ln 可以幫助我們轉換成 sigma。</li><li>將一個函數直接套上 ln =&gt; ln(f(x)) v.s f(x) ，ln(f(x)) 的值會縮小但正相關於 f(x)，雖然函數圖形會失真，但轉換後的特性不變，這點對我們的目標沒有嚴重的影響。</li><li>整個推導最後想求的值是 min of w，ln(f(x)) 會比 f(x) 更小，就這點而言選用 ln 是有幫助的。</li><li>綜上所述，ln(f(x)) 和 f(x) 的實質意義不盡相同，但部分特性保有一制，所以選擇做出這樣的轉換。</li></ol><p>min of w =&gt; (1/N)Σ(-ln(θ(y_n <em> w^T </em> x_n)), n = 1 to N)</p><p>min of w =&gt; (1/N)Σ(ln(1 + exp(y_n <em> w^T </em> x_n)), n = 1 to N)</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>标签：</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/machine-learning">machine learning</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="博文分页导航"><a class="pagination-nav__link pagination-nav__link--next" href="/blog/front-end-performance"><div class="pagination-nav__sublabel">较旧一篇</div><div class="pagination-nav__label">前端效能探討</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#何謂機器學習" class="table-of-contents__link toc-highlight">何謂機器學習</a></li><li><a href="#資料---結果--方法" class="table-of-contents__link toc-highlight">資料 -&gt; 結果 = 方法</a></li><li><a href="#可能信無限多種" class="table-of-contents__link toc-highlight">可能信無限多種</a></li><li><a href="#perceptron" class="table-of-contents__link toc-highlight">Perceptron</a></li><li><a href="#基於二元結果的機率---logistic-regression" class="table-of-contents__link toc-highlight">基於二元結果的機率 - logistic regression</a></li><li><a href="#執行上的困難以及折衷作法" class="table-of-contents__link toc-highlight">執行上的困難，以及折衷作法</a></li><li><a href="#sigmoid" class="table-of-contents__link toc-highlight">sigmoid</a></li><li><a href="#fx-in-logistic-regression" class="table-of-contents__link toc-highlight">f(x) in logistic regression</a><ul><li><a href="#likelihood" class="table-of-contents__link toc-highlight">Likelihood</a></li></ul></li><li><a href="#cross-entropy-error" class="table-of-contents__link toc-highlight">Cross-Entropy Error</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Social Media</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/allen-hsieh-29862b212" target="_blank" rel="noopener noreferrer" class="footer__link-item">Linkedin<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/Allen804347" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://leetcode.com/Allen804347/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Leetcode<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="mailto:allen804347@gmail.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Allen, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.c9a5b154.js"></script>
<script src="/assets/js/main.a7efb3ed.js"></script>
</body>
</html>